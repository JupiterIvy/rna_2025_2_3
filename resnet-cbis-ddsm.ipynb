{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1873742,"sourceType":"datasetVersion","datasetId":1115384}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install np_utils","metadata":{"_uuid":"df2e2c27-1fb3-4b11-8009-71f7ab8b5ac0","_cell_guid":"68cd157d-4051-40c3-9a41-66f0c636e411","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! python np_utils -v","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\nimport os\nfrom os import listdir\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport plotly.express as px\nimport seaborn as sns\n\nimport cv2\nfrom matplotlib.image import imread\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.preprocessing import image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n\nimport glob\nimport PIL\nfrom PIL import Image\nimport random\n\nrandom.seed(100)","metadata":{"_uuid":"5d173c91-4d76-45ef-99d7-7ec67c8b1945","_cell_guid":"86e3531e-0573-4f5b-b865-9fa503ed85a7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\nif len(physical_devices) > 0:\n    print(\"We got a GPU\")\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\nelse:\n    print(\"Sorry, no GPU for you...\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndataset_name = 'cbis-ddsm-breast-cancer-image-dataset' # Example dataset name\nsubfolder_name = 'jpeg/1.3.6.1.4.1.9590.100.1.2.316322277110955049538295115662287535438'\nimage_filename = '1-098.jpg' # Example image filename\n\ndataset_path = f'/kaggle/input/{dataset_name}/{subfolder_name}/'\nimage_path = os.path.join(dataset_path, image_filename)\n\ntry:\n    img = Image.open(image_path)\n    plt.imshow(img)\n    plt.title(f'Displaying: {image_filename}')\n    plt.axis('off')\n    plt.show()\n    print(f\"Successfully opened and displayed {image_filename}\")\nexcept FileNotFoundError:\n    print(f\"Error: Image not found at {image_path}. Please check the path.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")","metadata":{"_uuid":"d23b2fd4-c513-4b7b-b13a-38fd5358beeb","_cell_guid":"f0e4c2f3-f502-4e9c-90da-d15ffd37baf7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\nbase_dir = \"/kaggle/input/cbis-ddsm-breast-cancer-image-dataset\"\nimage_dir = os.path.join(base_dir, \"jpeg\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\ndicom_data = pd.read_csv(f\"{base_dir}/csv/dicom_info.csv\")\ncalc_df = pd.read_csv(f\"{base_dir}/csv/calc_case_description_train_set.csv\")\nmass_df = pd.read_csv(f\"{base_dir}/csv/mass_case_description_train_set.csv\")\ncalc_df_test = pd.read_csv(f\"{base_dir}/csv/calc_case_description_test_set.csv\")\nmass_df_test = pd.read_csv(f\"{base_dir}/csv/mass_case_description_test_set.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\ndicom_clean = dicom_data.copy()\n\ncols_to_drop = [\n    'PatientBirthDate','AccessionNumber','Columns','ContentDate','ContentTime',\n    'PatientSex','ReferringPhysicianName','Rows','SOPClassUID','SOPInstanceUID',\n    'StudyDate','StudyID','StudyTime','InstanceNumber',\n    'SeriesNumber'\n]\n\ndicom_clean.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\n\ndicom_clean['SeriesDescription'] = dicom_clean['SeriesDescription'].fillna(method='bfill')\ndicom_clean['Laterality'] = dicom_clean['Laterality'].fillna(method='bfill')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\ndicom_clean.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\ncalc = calc_df.copy()\ncalc = calc.rename(columns={\n    'calc type':'calc_type',\n    'calc distribution':'calc_distribution',\n    'image view':'image_view',\n    'left or right breast':'left_or_right_breast',\n    'breast density':'breast_density',\n    'abnormality type':'abnormality_type',\n    'abnormality id': 'abnormality_id',\n    'image file path': 'image_file_path',\n    'cropped image file path': 'cropped_image_file_path',\n    'ROI mask file path': 'ROI_mask_file_path'\n})\n\n# Converter para categorias\nfor col in ['pathology','calc_type','calc_distribution','abnormality_type',\n            'image_view','left_or_right_breast']:\n    if col in calc.columns:\n        calc[col] = calc[col].astype('category')\n\ncalc['calc_type'].fillna(method='bfill', inplace=True)\ncalc['calc_distribution'].fillna(method='bfill', inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\ncalc.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\nmass = mass_df.copy()\nmass = mass.rename(columns={\n    'mass shape':'mass_shape',\n    'mass margins':'mass_margins',\n    'image view':'image_view',\n    'left or right breast':'left_or_right_breast',\n    'abnormality type':'abnormality_type',\n    'abnormality id': 'abnormality_id',\n    'image file path': 'image_file_path',\n    'cropped image file path': 'cropped_image_file_path',\n    'ROI mask file path': 'ROI_mask_file_path'\n})\n\nfor col in ['mass_shape','mass_margins','pathology','abnormality_type',\n            'image_view','left_or_right_breast']:\n    if col in mass.columns:\n        mass[col] = mass[col].astype('category')\n\nmass['mass_shape'].fillna(method='bfill', inplace=True)\nmass['mass_margins'].fillna(method='bfill', inplace=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\nmass.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\ncalc_test = calc_df_test.copy()\ncalc_test = calc_test.rename(columns={\n    'calc type':'calc_type',\n    'calc distribution':'calc_distribution',\n    'image view':'image_view',\n    'left or right breast':'left_or_right_breast',\n    'breast density':'breast_density',\n    'abnormality type':'abnormality_type',\n    'abnormality id': 'abnormality_id',\n    'image file path': 'image_file_path',\n    'cropped image file path': 'cropped_image_file_path',\n    'ROI mask file path': 'ROI_mask_file_path'\n})\n\n# Converter para categorias\nfor col in ['pathology','calc_type','calc_distribution','abnormality_type',\n            'image_view','left_or_right_breast']:\n    if col in calc_test.columns:\n        calc_test[col] = calc_test[col].astype('category')\n\ncalc_test['calc_type'].fillna(method='bfill', inplace=True)\ncalc_test['calc_distribution'].fillna(method='bfill', inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\nmass_test = mass_df_test.copy()\nmass_test = mass_test.rename(columns={\n    'mass shape':'mass_shape',\n    'mass margins':'mass_margins',\n    'image view':'image_view',\n    'left or right breast':'left_or_right_breast',\n    'abnormality type':'abnormality_type',\n    'abnormality id': 'abnormality_id',\n    'image file path': 'image_file_path',\n    'cropped image file path': 'cropped_image_file_path',\n    'ROI mask file path': 'ROI_mask_file_path'\n})\n\nfor col in ['mass_shape','mass_margins','pathology','abnormality_type',\n            'image_view','left_or_right_breast']:\n    if col in mass_test.columns:\n        mass_test[col] = mass_test[col].astype('category')\n\nmass_test['mass_shape'].fillna(method='bfill', inplace=True)\nmass_test['mass_margins'].fillna(method='bfill', inplace=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\nfull_df = pd.concat([calc, calc_test, mass, mass_test], ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\nfull_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\n#checking common patients and pathologies between both dataframes \ncommon_patient_ids = calc[calc['patient_id'].isin(mass['patient_id']) &\n                          calc['patient_id'].isin(calc_test['patient_id']) &\n                          calc['patient_id'].isin(mass_test['patient_id'])]['patient_id']\n# common_patient_ids = calc[calc['patient_id'].isin(mass['patient_id'])]['patient_id']\nprint(common_patient_ids)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\n#this patient have both abnormality types\nfull_df[full_df['patient_id'] == 'P_00034']['cropped_image_file_path'][49]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nomes: Carla Lapa, Evelyn Bessa, Nezi Pimentel, Sandra Valcacer, Vitoria Almeida, Samira Souza\ndef map_pathology(p):\n    if p == \"MALIGNANT\":\n        return 1\n    else:\n        return 0\n\nfull_df['label'] = full_df['pathology'].apply(map_pathology)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dicom_clean.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# ================================================================\n# 1. Função para extrair identifiers corretos dos paths\n# ================================================================\ndef extract_uids(path):\n    \"\"\"\n    Extrai:\n    - dicom_patient_id  → ex: Calc-Training_P_00005_RIGHT_CC_1\n    - study_uid         → ex: 1.3.6.1.4.1.xxxxx... (primeiro UID)\n    - series_uid        → ex: 1.3.6.1.4.1.yyyyy... (segundo UID)\n    - filename          → ex: 000001.dcm\n    \"\"\"\n    if pd.isna(path):\n        return None, None, None, None\n    \n    parts = path.strip().split(\"/\")\n    \n    if len(parts) < 4:\n        return None, None, None, None\n    \n    dicom_patient_id = parts[0]\n    study_uid        = parts[1]\n    series_uid       = parts[2]\n    filename         = parts[3]\n\n    return dicom_patient_id, study_uid, series_uid, filename\n\n\n# ================================================================\n# 2. Aplicar ao full_df para criar colunas explícitas\n# ================================================================\nfull_df[\"dicom_patient_id\"] = full_df[\"cropped_image_file_path\"].apply(lambda x: extract_uids(x)[0])\nfull_df[\"study_uid\"]        = full_df[\"cropped_image_file_path\"].apply(lambda x: extract_uids(x)[1])\nfull_df[\"series_uid\"]       = full_df[\"cropped_image_file_path\"].apply(lambda x: extract_uids(x)[2])\nfull_df[\"dicom_filename\"]   = full_df[\"cropped_image_file_path\"].apply(lambda x: extract_uids(x)[3])\n\n# Remover entradas inválidas\nfull_df = full_df[full_df[\"dicom_patient_id\"].notna()]\n\nprint(\"full_df com UIDs extraídos:\", len(full_df))\nfull_df['mass_shape'] = full_df['mass_shape'].fillna(method='bfill')\nfull_df['mass_margins'] = full_df['mass_margins'].fillna(method='bfill')\n\n# ================================================================\n# 3. Preparar dicom_clean para merge\n# ================================================================\ndicom_key_cols = [\"PatientID\", \"StudyInstanceUID\", \"SeriesInstanceUID\", \"image_path\", \"SeriesDescription\"]\n\ndicom_clean_sub = dicom_clean[dicom_key_cols].copy()\n\ndicom_clean_sub = dicom_clean_sub.rename(columns={\n    \"PatientID\": \"dicom_patient_id\",\n    \"StudyInstanceUID\": \"study_uid\",\n    \"SeriesInstanceUID\": \"series_uid\",\n    \"image_path\": \"dicom_jpeg_path\"\n})\n\nprint(\"dicom_clean pronto para merge:\", len(dicom_clean_sub))\n\n\n# ================================================================\n# 4. MERGE: relação perfeita entre full_df e dicom_clean\n# ================================================================\nmerged_df = pd.merge(\n    full_df,\n    dicom_clean_sub,\n    on=[\"dicom_patient_id\", \"study_uid\", \"series_uid\"],\n    how=\"left\"\n)\n\nprint(\"Merged entries:\", len(merged_df))\nprint(\"JPEG real encontrado em:\", merged_df[\"dicom_jpeg_path\"].notna().sum())\n\n\n# ================================================================\n# 5. Filtrar somente entradas com JPEG existente (cropped não necessário)\n# ================================================================\n# merged_df[\"jpeg_exists\"] = merged_df[\"dicom_jpeg_path\"].apply(\n#     lambda p: os.path.exists(os.path.join(base_dir, p)) if isinstance(p, str) else False\n# )\n\n# final_df = merged_df.copy()\n\n# print(\"Final dataset (sem ROI, apenas JPEG válido):\", len(final_df))\n\n# # ================================================================\n# # 6. Caminho final absoluto para treinamento\n# # ================================================================\n# final_df[\"jpeg_full_path\"] = final_df[\"dicom_jpeg_path\"].apply(lambda p: os.path.join(base_dir, p))\n\nprint(merged_df[[\"dicom_jpeg_path\", \"pathology\", \"label\"]].head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#merged_df.head()\n#dicom_clean_sub[dicom_clean_sub['series_uid'] == '1.3.6.1.4.1.9590.100.1.2.393344010211719049419601138200355094682']\n#full_df[full_df['patient_id'] == 'P_00034']['cropped_image_file_path'][49]\nmerged_df[merged_df['patient_id'] == 'P_00034']\n#merged_df[merged_df['series_uid'] == '1.3.6.1.4.1.9590.100.1.2.40204365512880018321779759940450653990']\n#1.3.6.1.4.1.9590.100.1.2.40204365512880018321779759940450653990","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df.count()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df = merged_df[ merged_df[\"SeriesDescription\"] == \"cropped images\" ].copy()\nprint(filtered_df[\"SeriesDescription\"].value_counts())\nprint(len(filtered_df))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df[filtered_df['patient_id'] == 'P_00034']['dicom_jpeg_path'][98]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_df['mass_shape'] = filtered_df['mass_shape'].fillna(method='bfill')\nfiltered_df['mass_margins'] = filtered_df['mass_margins'].fillna(method='bfill')\nfiltered_df['calc_type'] = filtered_df['calc_type'].fillna(method='bfill')\nfiltered_df['calc_distribution'] = filtered_df['calc_distribution'].fillna(method='bfill')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols_to_drop = [\n    'dicom_filename','image_file_path','cropped_image_file_path','ROI_mask_file_path',\n]\n\nfiltered_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(filtered_df['abnormality_type'].value_counts())\nprint(filtered_df['label'].value_counts())\nprint(filtered_df['image_view'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optuna","metadata":{}},{"cell_type":"code","source":"!pip install optuna\n!pip install optuna-integration","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import EfficientNetV2M\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport optuna\nfrom optuna.integration import TFKerasPruningCallback\n\ndf = filtered_df.copy()\ndf = df[df[\"dicom_jpeg_path\"].notna()] \ndf['filepath'] = df['dicom_jpeg_path'].str.replace('CBIS-DDSM', base_dir)\n\nprint(\"Amostras válidas:\", len(df))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"label\"] = df[\"label\"].astype(str)\nX_paths = df[\"filepath\"].values\ny_labels = df[\"label\"].values.astype(int)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet152V2\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.callbacks import Callback\n\n\n# ================================================================\n# CALLBACK PARA MOSTRAR TREINAMENTO DETALHADO POR EPOCH\n# ================================================================\nclass EpochProgressCallback(Callback):\n    def __init__(self, trial_number, fold_number):\n        super().__init__()\n        self.trial_number = trial_number\n        self.fold_number = fold_number\n\n    def on_epoch_begin(self, epoch, logs=None):\n        print(f\"[Trial {self.trial_number} | Fold {self.fold_number}] \"\n              f\"Iniciando epoch {epoch + 1}\")\n\n    def on_epoch_end(self, epoch, logs=None):\n        print(f\"[Trial {self.trial_number} | Fold {self.fold_number}] \"\n              f\"Epoch {epoch + 1} — loss={logs.get('loss'):.4f}, \"\n              f\"acc={logs.get('accuracy'):.4f}, \"\n              f\"val_loss={logs.get('val_loss'):.4f}, \"\n              f\"val_acc={logs.get('val_accuracy'):.4f}\")\n\n\n# ================================================================\n# CONSTRUÇÃO DO MODELO (RESNET152V2)\n# ================================================================\ndef build_model(unfreeze_ratio, optimizer_name, lr, dropout):\n    base = ResNet152V2(weights=\"imagenet\", include_top=False, input_shape=(512, 512, 3))\n    base.trainable = False\n\n    # unfreeze percentual das últimas camadas\n    if unfreeze_ratio > 0:\n        n_layers = len(base.layers)\n        n_unfreeze = int(n_layers * unfreeze_ratio)\n        for layer in base.layers[-n_unfreeze:]:\n            layer.trainable = True\n\n    x = layers.GlobalAveragePooling2D()(base.output)\n    x = layers.Dropout(dropout)(x)\n    out = layers.Dense(1, activation=\"sigmoid\")(x)\n\n    model = models.Model(inputs=base.input, outputs=out)\n\n    if optimizer_name == \"adamw\":\n        optimizer = optimizers.AdamW(learning_rate=lr)\n    elif optimizer_name == \"adam\":\n        optimizer = optimizers.Adam(learning_rate=lr)\n    elif optimizer_name == \"rmsprop\":\n        optimizer = optimizers.RMSprop(learning_rate=lr)\n\n    model.compile(\n        optimizer=optimizer,\n        loss=\"binary_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model\n\n\n# ================================================================\n# DATAGENS\n# ================================================================\ndef build_datagen():\n    return ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=15,\n        horizontal_flip=True,\n        zoom_range=0.10,\n        width_shift_range=0.05,\n        height_shift_range=0.05,\n        fill_mode=\"nearest\"\n    )\n\ndef build_test_datagen():\n    return ImageDataGenerator(rescale=1./255)\n\n\n# ================================================================\n# OBJETIVO DO OPTUNA\n# ================================================================\ndef objective(trial):\n\n    unfreeze_ratio = trial.suggest_categorical(\"unfreeze_ratio\", [0.2, 0.4, 0.6, 1.0])\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 12])\n    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adamw\", \"adam\", \"rmsprop\"])\n    lr = trial.suggest_float(\"lr\", 1e-5, 5e-4, log=True)\n    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n    epochs = trial.suggest_int(\"epochs\", 3, 10)\n\n    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n    fold_accuracies = []\n\n    X = np.array(X_paths)\n    y = np.array(y_labels)\n\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        print(f\"\\n========== Trial {trial.number} — Fold {fold+1} ==========\")\n\n        train_gen = build_datagen().flow_from_dataframe(\n            dataframe=df.iloc[train_idx],\n            x_col=\"filepath\",\n            y_col=\"label\",\n            target_size=(512, 512),\n            class_mode=\"binary\",\n            batch_size=batch_size,\n            shuffle=True\n        )\n\n        val_gen = build_test_datagen().flow_from_dataframe(\n            dataframe=df.iloc[val_idx],\n            x_col=\"filepath\",\n            y_col=\"label\",\n            target_size=(512, 512),\n            class_mode=\"binary\",\n            batch_size=batch_size,\n            shuffle=False\n        )\n\n        model = build_model(unfreeze_ratio, optimizer_name, lr, dropout)\n\n        progress_callback = EpochProgressCallback(\n            trial_number=trial.number,\n            fold_number=fold + 1\n        )\n\n        history = model.fit(\n            train_gen,\n            validation_data=val_gen,\n            epochs=epochs,\n            verbose=0,  # silêncio do Keras; mostramos só via callback\n            callbacks=[progress_callback]\n        )\n\n        best_acc = max(history.history[\"val_accuracy\"])\n        fold_accuracies.append(best_acc)\n\n    return np.mean(fold_accuracies)\n\n\n# ================================================================\n# EXECUÇÃO DO OPTUNA\n# ================================================================\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=8)\n\nprint(\"Melhores parâmetros:\", study.best_params)\nprint(\"Melhor score:\", study.best_value)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, f1_score, recall_score, precision_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nimport pandas as pd\n\n###############################################################\n# 1. Hiperparâmetros definidos a partir da melhor Trial Optuna\n###############################################################\n\nUNFREEZE_RATIO = 0.4\nBATCH_SIZE = 12\nLR = 3.3988121810437836e-05\nDROPOUT = 0.2500453237976704\nEPOCHS = 9   # 9 era o best nas trials, mas agora usamos early stopping\nIMG_SIZE = 384\nN_FOLDS = 3","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Função de criação do modelo EfficientNetV2-M","metadata":{}},{"cell_type":"code","source":"def build_model(lr=LR, dropout=DROPOUT, unfreeze_ratio=UNFREEZE_RATIO):\n\n    base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2M(\n        include_top=False,\n        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n        weights=\"imagenet\",\n        pooling=None\n    )\n\n    total_layers = len(base_model.layers)\n    unfreeze_until = int(total_layers * unfreeze_ratio)\n\n    # Congela parte inicial da rede (se ratio < 1)\n    for i, layer in enumerate(base_model.layers):\n        layer.trainable = (i >= (total_layers - unfreeze_until))\n\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    x = tf.keras.applications.efficientnet_v2.preprocess_input(inputs)\n    x = base_model(x, training=True)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(dropout)(x)\n    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n\n    model = models.Model(inputs, outputs)\n\n    # AdamW otimizado\n    optimizer = tf.keras.optimizers.AdamW(learning_rate=lr)\n\n    model.compile(\n        optimizer=optimizer,\n        loss=\"binary_crossentropy\",\n        metrics=[\n            tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n            tf.keras.metrics.AUC(name=\"auc\"),\n            tf.keras.metrics.Precision(name=\"precision\"),\n            tf.keras.metrics.Recall(name=\"recall\")\n        ]\n    )\n\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data augmentation para treino","metadata":{}},{"cell_type":"code","source":"def build_datagen():\n    return ImageDataGenerator(\n        rescale=1./255,\n        horizontal_flip=True,\n        vertical_flip=True,\n        rotation_range=8,\n        width_shift_range=0.05,\n        height_shift_range=0.05,\n        brightness_range=[0.9, 1.1]\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n\nfinal_preds = []\nfinal_labels = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df, df[\"label\"])):\n    print(f\"\\n==================== Fold {fold+1}/{N_FOLDS} ====================\")\n\n    train_df = df.iloc[train_idx].reset_index(drop=True)\n    val_df = df.iloc[val_idx].reset_index(drop=True)\n\n    # Data generators\n    train_gen = build_datagen().flow_from_dataframe(\n        train_df,\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(IMG_SIZE, IMG_SIZE),\n        class_mode=\"binary\",\n        batch_size=BATCH_SIZE,\n        shuffle=True\n    )\n\n    val_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n        val_df,\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(IMG_SIZE, IMG_SIZE),\n        class_mode=\"binary\",\n        batch_size=BATCH_SIZE,\n        shuffle=False\n    )\n\n    # Monta o modelo\n    model = build_model()\n\n    # Callbacks\n    ckpt_path = f\"best_model_fold{fold+1}.h5\"\n    \n    callbacks = [\n        EarlyStopping(\n            monitor=\"val_auc\",\n            patience=5,\n            mode=\"max\",\n            restore_best_weights=True\n        ),\n        ModelCheckpoint(\n            ckpt_path,\n            monitor=\"val_auc\",\n            mode=\"max\",\n            save_best_only=True,\n            verbose=1\n        ),\n        ReduceLROnPlateau(\n            monitor=\"val_loss\",\n            factor=0.5,\n            patience=3,\n            verbose=1\n        )\n    ]\n\n    # Treinamento\n    history = model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=EPOCHS,\n        callbacks=callbacks,\n        verbose=1\n    )\n\n    # Predições do fold\n    preds = model.predict(val_gen).ravel()\n    final_preds.extend(preds)\n    final_labels.extend(val_df[\"label\"].values)\n\n    tf.keras.backend.clear_session()","metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###############################################################\n# 5. Métricas finais consolidadas\n###############################################################\n\nfinal_preds_bin = (np.array(final_preds) >= 0.5).astype(int)\nfinal_labels_arr = np.array(final_labels).astype(int)\n\nprint(\"\\n==================== Resultados Finais (K-Fold) ====================\\n\")\nprint(classification_report(final_labels_arr, final_preds_bin, digits=4))\n\nprint(\"F1-score:\", f1_score(final_labels_arr, final_preds_bin))\nprint(\"Recall:\", recall_score(final_labels_arr, final_preds_bin))\nprint(\"Precision:\", precision_score(final_labels_arr, final_preds_bin))\nprint(\"AUC:\", roc_auc_score(final_labels_arr, final_preds))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(type(final_labels_arr[0]))\nprint(type(final_preds_bin[0]))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}